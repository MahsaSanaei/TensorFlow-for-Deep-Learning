{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"28-lesson10-nlp_constructing_text_generation_model.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb","timestamp":1624346916279}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ph5eir3Pf-3z"},"source":["# Constructing a Text Generation Model\n"]},{"cell_type":"markdown","metadata":{"id":"7GbGfr_oLCat"},"source":["Using most of the techniques, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."]},{"cell_type":"markdown","metadata":{"id":"4aHK2CYygXom"},"source":["## Import TensorFlow and related functions"]},{"cell_type":"code","metadata":{"id":"2LmLTREBf5ng","executionInfo":{"status":"ok","timestamp":1624377619077,"user_tz":-270,"elapsed":1696,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Other imports for processing data\n","import string\n","import numpy as np\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GmLTO_dpgge9"},"source":["## Get the Dataset\n","\n","As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."]},{"cell_type":"code","metadata":{"id":"4Bf5FVHfganK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624377628809,"user_tz":-270,"elapsed":5060,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}},"outputId":"2574a05a-75be-4101-fde7-0c6632aec0de"},"source":["!wget --no-check-certificate \\\n","    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n","    -O /tmp/songdata.csv"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-06-22 16:00:23--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n","Resolving drive.google.com (drive.google.com)... 74.125.195.101, 74.125.195.138, 74.125.195.113, ...\n","Connecting to drive.google.com (drive.google.com)|74.125.195.101|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d6npn6hs3ejnkvdrftgsm13a1g1r0ms8/1624377600000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-06-22 16:00:27--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d6npn6hs3ejnkvdrftgsm13a1g1r0ms8/1624377600000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n","Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.135.132, 2607:f8b0:400e:c01::84\n","Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.135.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/csv]\n","Saving to: ‘/tmp/songdata.csv’\n","\n","/tmp/songdata.csv       [   <=>              ]  69.08M   141MB/s    in 0.5s    \n","\n","2021-06-22 16:00:28 (141 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gu1BTzMIS1oy"},"source":["## **First 10 Songs**\n","\n","Let's first look at just 10 songs from the dataset, and see how things perform."]},{"cell_type":"markdown","metadata":{"id":"fmb9rGaAUDO-"},"source":["### Preprocessing\n","\n","Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."]},{"cell_type":"code","metadata":{"id":"2AVAvyF_Vuh5","executionInfo":{"status":"ok","timestamp":1624377718374,"user_tz":-270,"elapsed":392,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}}},"source":["def tokenize_corpus(corpus, num_words=-1):\n","  # Fit a Tokenizer on the corpus\n","  if num_words > -1:\n","    tokenizer = Tokenizer(num_words=num_words)\n","  else:\n","    tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(corpus)\n","  return tokenizer\n","\n","def create_lyrics_corpus(dataset, field):\n","  # Remove all other punctuation\n","  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n","  # Make it lowercase\n","  dataset[field] = dataset[field].str.lower()\n","  # Make it one long string to split by line\n","  lyrics = dataset[field].str.cat()\n","  corpus = lyrics.split('\\n')\n","  # Remove any trailing whitespace\n","  for l in range(len(corpus)):\n","    corpus[l] = corpus[l].rstrip()\n","  # Remove any empty lines\n","  corpus = [l for l in corpus if l != '']\n","\n","  return corpus"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"apcEXp7WhVBs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624377759788,"user_tz":-270,"elapsed":1227,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}},"outputId":"01ad42b3-f1d8-49ae-d84d-56100aba4dd0"},"source":["# Read the dataset from csv - just first 10 songs for now\n","dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n","# Create the corpus using the 'text' column containing lyrics\n","corpus = create_lyrics_corpus(dataset, 'text')\n","# Tokenize the corpus\n","tokenizer = tokenize_corpus(corpus)\n","\n","total_words = len(tokenizer.word_index) + 1\n","\n","print(tokenizer.word_index)\n","print(total_words)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n","495\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WH-h8OXJfSTg","executionInfo":{"status":"ok","timestamp":1624378334660,"user_tz":-270,"elapsed":572,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}},"outputId":"149bca70-7642-4b94-a322-c7afd75418d0"},"source":["print(corpus[:3])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["['look at her face its a wonderful face', 'and it means something special to me', 'look at the way that she smiles when she sees me']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v9x68iN_X6FK"},"source":["### Create Sequences and Labels\n","\n","After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."]},{"cell_type":"code","metadata":{"id":"QmlTsUqfikVO","executionInfo":{"status":"ok","timestamp":1624377862147,"user_tz":-270,"elapsed":441,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}}},"source":["sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tsequences.append(n_gram_sequence)\n","\n","# Pad sequences for equal input length \n","max_sequence_len = max([len(seq) for seq in sequences])\n","sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# Split sequences between the \"input\" sequence and \"output\" predicted word\n","input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n","# One-hot encode the labels\n","one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zsmu3aEId49i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624377867143,"user_tz":-270,"elapsed":473,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}},"outputId":"3aac32ba-f9fe-4205-accf-a7d7fc30178c"},"source":["# Check out how some of our data is being stored\n","# The Tokenizer has just a single index per word\n","print(tokenizer.word_index['know'])\n","print(tokenizer.word_index['feeling'])\n","# Input sequences will have multiple indexes\n","print(input_sequences[5])\n","print(input_sequences[6])\n","# And the one hot labels will be as long as the full spread of tokenized words\n","print(one_hot_labels[5])\n","print(one_hot_labels[6])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["32\n","97\n","[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n","   4]\n","[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n"," 287]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-1TAJMlmfO8r"},"source":["### Train a Text Generation Model\n","\n","Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n","\n","From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."]},{"cell_type":"code","metadata":{"id":"G1YXuxIqfygN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624378001953,"user_tz":-270,"elapsed":105641,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}},"outputId":"de3d14fe-1a0e-46af-ad28-5aa0510e8c23"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n","\n","model = Sequential()\n","model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(20)))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","62/62 [==============================] - 9s 7ms/step - loss: 6.0175 - accuracy: 0.0293\n","Epoch 2/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.4500 - accuracy: 0.0394\n","Epoch 3/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.3700 - accuracy: 0.0409\n","Epoch 4/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.3123 - accuracy: 0.0404\n","Epoch 5/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.2318 - accuracy: 0.0454\n","Epoch 6/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.1507 - accuracy: 0.0631\n","Epoch 7/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.0779 - accuracy: 0.0595\n","Epoch 8/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.0120 - accuracy: 0.0651\n","Epoch 9/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.9483 - accuracy: 0.0701\n","Epoch 10/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.8741 - accuracy: 0.0822\n","Epoch 11/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.7926 - accuracy: 0.0898\n","Epoch 12/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.6939 - accuracy: 0.0969\n","Epoch 13/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.6032 - accuracy: 0.0979\n","Epoch 14/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.4992 - accuracy: 0.1085\n","Epoch 15/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.4108 - accuracy: 0.1125\n","Epoch 16/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.3245 - accuracy: 0.1297\n","Epoch 17/200\n","62/62 [==============================] - 0s 8ms/step - loss: 4.2446 - accuracy: 0.1276\n","Epoch 18/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.1647 - accuracy: 0.1438\n","Epoch 19/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.0888 - accuracy: 0.1443\n","Epoch 20/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.0271 - accuracy: 0.1625\n","Epoch 21/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.9687 - accuracy: 0.1736\n","Epoch 22/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.8715 - accuracy: 0.1958\n","Epoch 23/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.7973 - accuracy: 0.2094\n","Epoch 24/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.7410 - accuracy: 0.2064\n","Epoch 25/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.6681 - accuracy: 0.2427\n","Epoch 26/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.6043 - accuracy: 0.2477\n","Epoch 27/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.5330 - accuracy: 0.2639\n","Epoch 28/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.4845 - accuracy: 0.2830\n","Epoch 29/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.4207 - accuracy: 0.2820\n","Epoch 30/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.3677 - accuracy: 0.3032\n","Epoch 31/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.2916 - accuracy: 0.3098\n","Epoch 32/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.2439 - accuracy: 0.3249\n","Epoch 33/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.1929 - accuracy: 0.3421\n","Epoch 34/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.1191 - accuracy: 0.3582\n","Epoch 35/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.0607 - accuracy: 0.3628\n","Epoch 36/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.0047 - accuracy: 0.3819\n","Epoch 37/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.9471 - accuracy: 0.3925\n","Epoch 38/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.9036 - accuracy: 0.4057\n","Epoch 39/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.8521 - accuracy: 0.4238\n","Epoch 40/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.8055 - accuracy: 0.4203\n","Epoch 41/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.7460 - accuracy: 0.4374\n","Epoch 42/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.6978 - accuracy: 0.4506\n","Epoch 43/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.6480 - accuracy: 0.4511\n","Epoch 44/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.6070 - accuracy: 0.4667\n","Epoch 45/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.5635 - accuracy: 0.4753\n","Epoch 46/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.5207 - accuracy: 0.4828\n","Epoch 47/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.4747 - accuracy: 0.4879\n","Epoch 48/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.4499 - accuracy: 0.4924\n","Epoch 49/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.4036 - accuracy: 0.5000\n","Epoch 50/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.3549 - accuracy: 0.5151\n","Epoch 51/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.3681 - accuracy: 0.5030\n","Epoch 52/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.3227 - accuracy: 0.5212\n","Epoch 53/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.2466 - accuracy: 0.5343\n","Epoch 54/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.2006 - accuracy: 0.5505\n","Epoch 55/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.1552 - accuracy: 0.5545\n","Epoch 56/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.1191 - accuracy: 0.5646\n","Epoch 57/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.0928 - accuracy: 0.5752\n","Epoch 58/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.0533 - accuracy: 0.5802\n","Epoch 59/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.0214 - accuracy: 0.5827\n","Epoch 60/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.0003 - accuracy: 0.5928\n","Epoch 61/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.9699 - accuracy: 0.5928\n","Epoch 62/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.9313 - accuracy: 0.6100\n","Epoch 63/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.9044 - accuracy: 0.6034\n","Epoch 64/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.8615 - accuracy: 0.6196\n","Epoch 65/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.8335 - accuracy: 0.6130\n","Epoch 66/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7906 - accuracy: 0.6266\n","Epoch 67/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7639 - accuracy: 0.6266\n","Epoch 68/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7350 - accuracy: 0.6382\n","Epoch 69/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7063 - accuracy: 0.6478\n","Epoch 70/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.6771 - accuracy: 0.6514\n","Epoch 71/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.6593 - accuracy: 0.6569\n","Epoch 72/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.6349 - accuracy: 0.6625\n","Epoch 73/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.6199 - accuracy: 0.6564\n","Epoch 74/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5990 - accuracy: 0.6609\n","Epoch 75/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5739 - accuracy: 0.6685\n","Epoch 76/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5567 - accuracy: 0.6766\n","Epoch 77/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5216 - accuracy: 0.6811\n","Epoch 78/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4838 - accuracy: 0.6917\n","Epoch 79/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4587 - accuracy: 0.6993\n","Epoch 80/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4355 - accuracy: 0.7038\n","Epoch 81/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4163 - accuracy: 0.7048\n","Epoch 82/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4095 - accuracy: 0.7008\n","Epoch 83/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.3826 - accuracy: 0.7109\n","Epoch 84/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.3575 - accuracy: 0.7175\n","Epoch 85/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.3391 - accuracy: 0.7180\n","Epoch 86/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.3185 - accuracy: 0.7205\n","Epoch 87/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.3032 - accuracy: 0.7270\n","Epoch 88/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2941 - accuracy: 0.7291\n","Epoch 89/200\n","62/62 [==============================] - 0s 8ms/step - loss: 1.2947 - accuracy: 0.7195\n","Epoch 90/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2520 - accuracy: 0.7311\n","Epoch 91/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2231 - accuracy: 0.7432\n","Epoch 92/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1967 - accuracy: 0.7528\n","Epoch 93/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1784 - accuracy: 0.7518\n","Epoch 94/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1715 - accuracy: 0.7563\n","Epoch 95/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1482 - accuracy: 0.7608\n","Epoch 96/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1425 - accuracy: 0.7629\n","Epoch 97/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1314 - accuracy: 0.7649\n","Epoch 98/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2450 - accuracy: 0.7281\n","Epoch 99/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1575 - accuracy: 0.7523\n","Epoch 100/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1455 - accuracy: 0.7482\n","Epoch 101/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1296 - accuracy: 0.7503\n","Epoch 102/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1192 - accuracy: 0.7598\n","Epoch 103/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0868 - accuracy: 0.7674\n","Epoch 104/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0420 - accuracy: 0.7830\n","Epoch 105/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0188 - accuracy: 0.7901\n","Epoch 106/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0053 - accuracy: 0.7901\n","Epoch 107/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.9786 - accuracy: 0.7982\n","Epoch 108/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.9628 - accuracy: 0.8052\n","Epoch 109/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.9505 - accuracy: 0.8052\n","Epoch 110/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.9476 - accuracy: 0.8083\n","Epoch 111/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.9331 - accuracy: 0.8103\n","Epoch 112/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.9180 - accuracy: 0.8098\n","Epoch 113/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.9095 - accuracy: 0.8108\n","Epoch 114/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8966 - accuracy: 0.8174\n","Epoch 115/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8925 - accuracy: 0.8123\n","Epoch 116/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.8810 - accuracy: 0.8143\n","Epoch 117/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8644 - accuracy: 0.8234\n","Epoch 118/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8539 - accuracy: 0.8224\n","Epoch 119/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8415 - accuracy: 0.8259\n","Epoch 120/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8325 - accuracy: 0.8249\n","Epoch 121/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8152 - accuracy: 0.8285\n","Epoch 122/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8087 - accuracy: 0.8259\n","Epoch 123/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8022 - accuracy: 0.8305\n","Epoch 124/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7911 - accuracy: 0.8325\n","Epoch 125/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7775 - accuracy: 0.8396\n","Epoch 126/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7668 - accuracy: 0.8375\n","Epoch 127/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7586 - accuracy: 0.8431\n","Epoch 128/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7478 - accuracy: 0.8451\n","Epoch 129/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7449 - accuracy: 0.8426\n","Epoch 130/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7335 - accuracy: 0.8451\n","Epoch 131/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7254 - accuracy: 0.8486\n","Epoch 132/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7218 - accuracy: 0.8471\n","Epoch 133/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7247 - accuracy: 0.8451\n","Epoch 134/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7082 - accuracy: 0.8461\n","Epoch 135/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7187 - accuracy: 0.8431\n","Epoch 136/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6966 - accuracy: 0.8441\n","Epoch 137/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6887 - accuracy: 0.8481\n","Epoch 138/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6978 - accuracy: 0.8431\n","Epoch 139/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7189 - accuracy: 0.8370\n","Epoch 140/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7557 - accuracy: 0.8300\n","Epoch 141/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7758 - accuracy: 0.8224\n","Epoch 142/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7175 - accuracy: 0.8391\n","Epoch 143/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7483 - accuracy: 0.8184\n","Epoch 144/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6947 - accuracy: 0.8401\n","Epoch 145/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6718 - accuracy: 0.8471\n","Epoch 146/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6546 - accuracy: 0.8507\n","Epoch 147/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6340 - accuracy: 0.8587\n","Epoch 148/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6343 - accuracy: 0.8547\n","Epoch 149/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6154 - accuracy: 0.8628\n","Epoch 150/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.6079 - accuracy: 0.8658\n","Epoch 151/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5954 - accuracy: 0.8643\n","Epoch 152/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5905 - accuracy: 0.8698\n","Epoch 153/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5907 - accuracy: 0.8688\n","Epoch 154/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5821 - accuracy: 0.8693\n","Epoch 155/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.8678\n","Epoch 156/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5718 - accuracy: 0.8643\n","Epoch 157/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5630 - accuracy: 0.8713\n","Epoch 158/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5547 - accuracy: 0.8668\n","Epoch 159/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5468 - accuracy: 0.8734\n","Epoch 160/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.8708\n","Epoch 161/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.8744\n","Epoch 162/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.8749\n","Epoch 163/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5334 - accuracy: 0.8713\n","Epoch 164/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5318 - accuracy: 0.8724\n","Epoch 165/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.8794\n","Epoch 166/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.8734\n","Epoch 167/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5539 - accuracy: 0.8658\n","Epoch 168/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5208 - accuracy: 0.8749\n","Epoch 169/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5109 - accuracy: 0.8759\n","Epoch 170/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.8794\n","Epoch 171/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4923 - accuracy: 0.8764\n","Epoch 172/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4925 - accuracy: 0.8809\n","Epoch 173/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4933 - accuracy: 0.8749\n","Epoch 174/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5127 - accuracy: 0.8703\n","Epoch 175/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5054 - accuracy: 0.8739\n","Epoch 176/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.8784\n","Epoch 177/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.8794\n","Epoch 178/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4696 - accuracy: 0.8799\n","Epoch 179/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4641 - accuracy: 0.8809\n","Epoch 180/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4571 - accuracy: 0.8814\n","Epoch 181/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.8835\n","Epoch 182/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.8835\n","Epoch 183/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.8865\n","Epoch 184/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.8860\n","Epoch 185/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8865\n","Epoch 186/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.8814\n","Epoch 187/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.8875\n","Epoch 188/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.8900\n","Epoch 189/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.8885\n","Epoch 190/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8865\n","Epoch 191/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.8587\n","Epoch 192/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5443 - accuracy: 0.8582\n","Epoch 193/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.8759\n","Epoch 194/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.8819\n","Epoch 195/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8814\n","Epoch 196/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.8880\n","Epoch 197/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8850\n","Epoch 198/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8870\n","Epoch 199/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8885\n","Epoch 200/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8920\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AXVFpoREhV6Y"},"source":["### View the Training Graph"]},{"cell_type":"code","metadata":{"id":"aeSNfS7uhch0","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1624378030084,"user_tz":-270,"elapsed":472,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}},"outputId":"616e92c7-6894-4db7-c850-b0a3ea0c267f"},"source":["import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.show()\n","\n","plot_graphs(history, 'accuracy')"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"1rAgRpxYhjpB"},"source":["### Generate new lyrics!\n","\n","It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."]},{"cell_type":"code","metadata":{"id":"DC7zfcgviDTp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624378131174,"user_tz":-270,"elapsed":4513,"user":{"displayName":"mahsa sanaei","photoUrl":"","userId":"09052074905704490784"}},"outputId":"2e5d529e-5ccf-467e-dc54-7fa1c58ffb98"},"source":["seed_text = \"im feeling chills\"\n","next_words = 100\n","  \n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["im feeling chills me to the bone the blown out of still candle me wait me ways park sky new break am do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do what could i do\n"],"name":"stdout"}]}]}